<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="title" content="TE-NeRF: Triplane-Enhanced Neural Radiance Field for Artifact-Free Human Rendering">
  <meta name="description" content="TE-NeRF integrates SMPL-anchored Triplane features with adaptive density blending to reduce artifacts and improve geometric consistency in human NeRF rendering.">
  <meta name="keywords" content="NeRF, Human Rendering, Triplane, SMPL, Neural Radiance Fields, HumanNeRF, Gaussian Splatting, 3D Reconstruction">
  <meta name="author" content="Sadia Mubashshira, Kevin Desai">

  <meta property="og:site_name" content="UTSA VIRLab">
  <meta property="og:title" content="TE-NeRF: Triplane-Enhanced Neural Radiance Field for Artifact-Free Human Rendering">
  <meta property="og:description" content="Artifact-free human neural rendering using SMPL-anchored Triplane features and adaptive density blending.">
  <meta property="og:url" content="https://utsavirlab.github.io/te-nerf">
  <meta property="og:image" content="static/images/social_preview.png">

  <meta name="twitter:title" content="TE-NeRF: Artifact-Free Human Neural Rendering">
  <meta name="twitter:description" content="Triplane-enhanced NeRF for artifact-free dynamic human rendering.">
  <meta name="twitter:image" content="static/images/social_preview.png">

  <meta name="citation_title" content="TE-NeRF: Triplane-Enhanced Neural Radiance Field for Artifact-Free Human Rendering">
  <meta name="citation_author" content="Mubashshira, Sadia">
  <meta name="citation_author" content="Desai, Kevin">
  <meta name="citation_publication_date" content="2025">
  <meta name="citation_conference_title" content="WACV Workshop 2025">

  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>PAPER_TITLE - AUTHOR_NAMES | Academic Research</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "PAPER_TITLE",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "FIRST_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      },
      {
        "@type": "Person",
        "name": "SECOND_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
  "abstract": "Rendering high-fidelity human avatars from monocular video with accurate surface details is crucial for applications in virtual reality, digital entertainment, and telepresence. While neural radiance field (NeRF) based models have shown promise in capturing human body representations, they often fail to render fine-grained details, such as cloth wrinkles and facial contours, resulting in noticeable artifacts outside the human body that undermine realism. Existing approaches lack the capability to achieve both detailed texture representation and seamless surface geometry. To address these limitations, we propose TE-NeRF, an enhanced framework that integrates Triplane features to improve detail accuracy and reduce artifacts. By associating Triplane-based features with each SMPL vertex and processing them through a density MLP, our method achieves precise representation of texture and geometry. An adaptive weight blending mechanism dynamically combines vertex-specific and ray-sampled densities, enabling a balance between detail preservation and smoothness in rendering. Additionally, a silhouette loss is introduced to reinforce alignment, particularly in complex regions like clothing edges and facial contours. Our approach reduces rendering artifacts compared to state-of-the-art methods, though with a slight trade-off in cloth detail sharpness, resulting in visually coherent human renderings validated through extensive experiments.",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <!-- More Works Dropdown -->
  <div class="more-works-container">
    <button class="more-works-btn" onclick="toggleMoreWorks()" title="View More Works from Our Lab">
      <i class="fas fa-flask"></i>
      More Works
      <i class="fas fa-chevron-down dropdown-arrow"></i>
    </button>
    <div class="more-works-dropdown" id="moreWorksDropdown">
      <div class="dropdown-header">
        <h4>More Works from Our Lab</h4>
        <button class="close-btn" onclick="toggleMoreWorks()">
          <i class="fas fa-times"></i>
        </button>
      </div>
      <div class="works-list">
        <!-- TODO: Replace with your lab's related works -->
        <a href="https://arxiv.org/abs/PAPER_ID_1" class="work-item" target="_blank">
          <div class="work-info">
            <!-- TODO: Replace with actual paper title -->
            <h5>Paper Title 1</h5>
            <!-- TODO: Replace with brief description -->
            <p>Brief description of the work and its main contribution.</p>
            <!-- TODO: Replace with venue and year -->
            <span class="work-venue">Conference/Journal 2024</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <!-- TODO: Add more related works or remove extra items -->
        <a href="https://arxiv.org/abs/PAPER_ID_2" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Paper Title 2</h5>
            <p>Brief description of the work and its main contribution.</p>
            <span class="work-venue">Conference/Journal 2023</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="https://arxiv.org/abs/PAPER_ID_3" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Paper Title 3</h5>
            <p>Brief description of the work and its main contribution.</p>
            <span class="work-venue">Conference/Journal 2023</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
      </div>
    </div>
  </div>

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- TODO: Replace with your paper title -->
            <h1 class="title is-1 publication-title">
            TE-NeRF: Triplane-Enhanced Neural Radiance Field for Artifact-Free Human Rendering
            </h1>

            <div class="is-size-5 publication-authors">
              <!-- TODO: Replace with your paper authors and their personal links -->
              <span class="author-block">
                 <a href="https://sadia-mubashshira.github.io" target="_blank">Sadia Mubashshira</a>,
              </span>
             <span class="author-block">
                <a href="https://www.utsa.edu" target="_blank">Kevin Desai</a>
             </span>
            </div>

	    <div class="is-size-5 publication-authors">
	    	<span class="author-block">
	    	    University of Texas at San Antonio <br>
	      	    WACV Workshop 2025
	     	</span>
	    </div>


                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- TODO: Update with your arXiv paper ID -->
                      <span class="link-block">
                        <a href="https://openaccess.thecvf.com/content/WACV2025W/ImageQuality/papers/Mubashshira_TE-NeRF_Triplane-Enhanced_Neural_Radiance_Field_for_Artifact-Free_Human_Rendering_WACVW_2025_paper.pdf" target="_blank" rel="noopener"
                          class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary button removed -->

                  <!-- TODO: Replace with your GitHub repository URL -->
                  <span class="link-block">
                    <a href="https://github.com/UTSA-VIRLab/TE-NeRF" target="_blank" rel="noopener"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- arXiv/archive button removed -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<!--<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%" preload="metadata">
        <source src="static/videos/banner_video.mp4" type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section>-->
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- Paper abstract: TE-NeRF -->
          <p>
            Rendering high-fidelity human avatars from monocular video with accurate surface details is crucial for applications in virtual reality, digital entertainment, and telepresence. While neural radiance field (NeRF) based models have shown promise in capturing human body representations, they often fail to render fine-grained details, such as cloth wrinkles and facial contours, resulting in noticeable artifacts outside the human body that undermine realism. Existing approaches lack the capability to achieve both detailed texture representation and seamless surface geometry. To address these limitations, we propose TE-NeRF, an enhanced framework that integrates Triplane features to improve detail accuracy and reduce artifacts. By associating Triplane-based features with each SMPL vertex and processing them through a density MLP, our method achieves precise representation of texture and geometry. An adaptive weight blending mechanism dynamically combines vertex-specific and ray-sampled densities, enabling a balance between detail preservation and smoothness in rendering. Additionally, a silhouette loss is introduced to reinforce alignment, particularly in complex regions like clothing edges and facial contours. Our approach reduces rendering artifacts compared to state-of-the-art methods, though with a slight trade-off in cloth detail sharpness, resulting in visually coherent human renderings validated through extensive experiments.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<!--<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <img src="static/images/carousel1.jpg" alt="First research result visualization" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          First image description.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/carousel2.jpg" alt="Second research result visualization" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Second image description.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/carousel3.jpg" alt="Third research result visualization" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
         Third image description.
       </h2>
     </div>
     <div class="item">
      <img src="static/images/carousel4.jpg" alt="Fourth research result visualization" loading="lazy"/>
      <h2 class="subtitle has-text-centered">
        Fourth image description.
      </h2>
    </div>
  </div>
</div>
</div>
</section>-->
<!-- End image carousel -->




<!-- Youtube video -->
<!-- Youtube video (commented out) -->
<!--
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <!--<h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">

          <div class="publication-video">
            <!-- TODO: Replace with your YouTube video ID -->
           <!-- <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
-->
<!-- End youtube video -->

<!-- Overview -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Overview</h2>
          <div class="content has-text-justified">
            <p>
              The framework synthesizes photorealistic renderings of dynamic humans in arbitrary poses by integrating multiple components. The input consists of an image sequence, SMPL body pose parameters (J, Ω), and camera parameters. The Pose Correction Module refines SMPL parameters to align observed and canonical spaces. The Motion Field Module decomposes motion into skeletal and non-rigid deformations, outputting the corrected position ∆(x). The Ray Regressor predicts the canonical density σr and color c for each point in the canonical space. Simultaneously, the Triplane Density MLP generates SMPL-aligned density values σt using spatially-aware Triplane features. Finally, the Adaptive Blending Module combines σr and σt using a learnable blending parameter, ensuring robust density estimation for volume rendering. The output is a photorealistic rendering of the human subject, free from artifacts and inconsistencies.
            </p>
          </div>
          <figure class="image">
            <img src="static/images/model-nerf.png" alt="TE-NeRF overview" loading="lazy"/>
          </figure>
          <h3 class="subtitle mt-4">TE-NeRF overview: Triplane-enhanced representation and adaptive density blending</h3>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End overview -->

<!-- Quantitative results -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container is-fluid px-6">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Quantitative Results</h2>
          <div class="content has-text-justified">
            <p>
              Quantitative comparison of individual subjects from the ZJU-MoCap dataset. LPIPS* = LPIPS &times; 10<sup>3</sup>. The best metric values are highlighted in green and the second-best in orange.
            </p>
          </div>
          <div class="table-container">
            <table class="table is-fullwidth is-striped is-bordered is-hoverable">
              <thead>
                <tr>
                  <th rowspan="2">Method</th>
                  <th colspan="3">Subject 377</th>
                  <th colspan="3">Subject 386</th>
                  <th colspan="3">Subject 387</th>
                </tr>
                <tr>
                  <th>PSNR ↑</th>
                  <th>SSIM ↑</th>
                  <th>LPIPS* ↓</th>
                  <th>PSNR ↑</th>
                  <th>SSIM ↑</th>
                  <th>LPIPS* ↓</th>
                  <th>PSNR ↑</th>
                  <th>SSIM ↑</th>
                  <th>LPIPS* ↓</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Neural Body</td>
                  <td>29.11</td>
                  <td style="background:#ffe6cc">0.9674</td>
                  <td>40.95</td>
                  <td>30.54</td>
                  <td style="background:#ffe6cc">0.9678</td>
                  <td>46.43</td>
                  <td>27.00</td>
                  <td>0.9518</td>
                  <td>59.47</td>
                </tr>
                <tr>
                  <td>HumanNeRF</td>
                  <td style="background:#d7f3d7">30.41</td>
                  <td style="background:#d7f3d7">0.9743</td>
                  <td style="background:#d7f3d7">24.06</td>
                  <td style="background:#d7f3d7">33.20</td>
                  <td style="background:#d7f3d7">0.9752</td>
                  <td style="background:#d7f3d7">28.99</td>
                  <td style="background:#d7f3d7">28.18</td>
                  <td style="background:#d7f3d7">0.9632</td>
                  <td style="background:#d7f3d7">35.58</td>
                </tr>
                <tr>
                  <td><strong>TE-NeRF</strong></td>
                  <td style="background:#ffe6cc">29.79</td>
                  <td>0.9656</td>
                  <td style="background:#ffe6cc">29.41</td>
                  <td style="background:#ffe6cc">32.73</td>
                  <td>0.9605</td>
                  <td style="background:#ffe6cc">36.30</td>
                  <td style="background:#ffe6cc">27.86</td>
                  <td style="background:#ffe6cc">0.9596</td>
                  <td style="background:#ffe6cc">39.87</td>
                </tr>
                <tr>
                  <td colspan="10">&nbsp;</td>
                </tr>
                <tr>
                  <th rowspan="2">Method</th>
                  <th colspan="3">Subject 392</th>
                  <th colspan="3">Subject 393</th>
                  <th colspan="3">Subject 394</th>
                </tr>
                <tr>
                  <th>PSNR ↑</th>
                  <th>SSIM ↑</th>
                  <th>LPIPS* ↓</th>
                  <th>PSNR ↑</th>
                  <th>SSIM ↑</th>
                  <th>LPIPS* ↓</th>
                  <th>PSNR ↑</th>
                  <th>SSIM ↑</th>
                  <th>LPIPS* ↓</th>
                </tr>
                <tr>
                  <td>Neural Body</td>
                  <td>30.10</td>
                  <td style="background:#ffe6cc">0.9642</td>
                  <td>53.27</td>
                  <td style="background:#ffe6cc">28.61</td>
                  <td style="background:#ffe6cc">0.9590</td>
                  <td style="background:#ffe6cc">59.05</td>
                  <td>29.10</td>
                  <td style="background:#ffe6cc">0.9593</td>
                  <td>54.55</td>
                </tr>
                <tr>
                  <td>HumanNeRF</td>
                  <td style="background:#d7f3d7">31.04</td>
                  <td style="background:#d7f3d7">0.9705</td>
                  <td style="background:#d7f3d7">32.12</td>
                  <td style="background:#d7f3d7">28.31</td>
                  <td style="background:#d7f3d7">0.9603</td>
                  <td style="background:#d7f3d7">36.72</td>
                  <td style="background:#d7f3d7">30.31</td>
                  <td style="background:#d7f3d7">0.9642</td>
                  <td style="background:#d7f3d7">32.89</td>
                </tr>
                <tr>
                  <td><strong>TE-NeRF</strong></td>
                  <td style="background:#ffe6cc">30.23</td>
                  <td>0.9540</td>
                  <td style="background:#ffe6cc">41.54</td>
                  <td>26.66</td>
                  <td>0.9284</td>
                  <td>65.16</td>
                  <td style="background:#ffe6cc">29.68</td>
                  <td>0.9476</td>
                  <td style="background:#ffe6cc">41.22</td>
                </tr>
              </tbody>
            </table>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End quantitative results -->



<!-- Qualitative results -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Qualitative Results</h2>
          <div class="content has-text-justified">
            <p>
              Qualitative comparisons illustrate TE-NeRF's improvements in reducing rendering artifacts while maintaining coherent surface geometry. The image below shows representative results: our Triplane-anchored density blending suppresses spurious background artifacts and improves silhouette alignment, particularly around clothing edges and facial contours. There is a small trade-off in cloth-detail sharpness in some cases, but overall visual coherence and artifact reduction are markedly improved. Refer to the figure for side-by-side examples and annotations.
            </p>
          </div>
          <figure class="image">
            <img src="static/images/qualitative-results.png" alt="Qualitative comparison results" loading="lazy"/>
          </figure>
          <h3 class="subtitle mt-4">Qualitative comparison: artifact reduction and silhouette alignment</h3>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End qualitative results -->

<!-- Video carousel -->
<!--<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
         
          <video poster="" id="video1" controls muted loop height="100%" preload="metadata">
           
            <source src="static/videos/carousel1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/carousel2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/carousel3.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>-->
<!-- End video carousel -->






<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <!-- TODO: Replace with your poster PDF -->
      <iframe  src="static/pdf/TE-NeRF_Poster.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@inproceedings{mubashshira2025tenerf,
  title={TE-NeRF: Triplane-Enhanced Neural Radiance Field for Artifact-Free Human Rendering},
  author={Mubashshira, Sadia and Desai, Kevin},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) Workshops},
  year={2025}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <div class="footer-brand has-text-centered" style="margin-bottom:1rem;">
            <p class="is-size-5 has-text-weight-semibold">
              <a href="https://utsa-virlab.github.io/" target="_blank" rel="noopener">UTSA VIRLab</a>
              &nbsp;&middot;&nbsp;
              <a href="https://www.utsa.edu/" target="_blank" rel="noopener">University of Texas at San Antonio</a>
            </p>
            <p class="is-size-6">Template adapted from <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank" rel="noopener">Academic Project Page Template</a></p>
          </div>


        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
